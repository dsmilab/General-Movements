{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T07:29:49.072102Z",
     "start_time": "2019-01-28T07:29:48.286446Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import random_shift, img_to_array\n",
    "import PIL.ImageOps\n",
    "\n",
    "import skimage\n",
    "from skimage.io import imshow, imread\n",
    "from skimage.color import rgb2grey\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T07:29:49.075873Z",
     "start_time": "2019-01-28T07:29:49.073445Z"
    }
   },
   "outputs": [],
   "source": [
    "TRAIN_DIRECTORY_PATH = '../data/mnist/train_set/'\n",
    "TEST_DIRECTORY_PATH = '../data/mnist/test_set/'\n",
    "\n",
    "NUM_CLASSES = 11\n",
    "IMG_ROWS, IMG_COLS = 15, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T07:29:51.917758Z",
     "start_time": "2019-01-28T07:29:49.077519Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (9393, 15, 10, 1)\n",
      "9393 train samples\n",
      "2310 test samples\n"
     ]
    }
   ],
   "source": [
    "x_train = []\n",
    "x_test = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "\n",
    "for digit in range(NUM_CLASSES):\n",
    "    directory = TRAIN_DIRECTORY_PATH + str(digit) + '/'\n",
    "    files = next(os.walk(directory))[2]\n",
    "    \n",
    "    for filename in files:\n",
    "        img = imread(directory + filename)\n",
    "        img = skimage.img_as_float(img)\n",
    "        imgs = [\n",
    "            random_shift(img, wrg=0.1, hrg=0.3, row_axis=0,\n",
    "                         col_axis=1, channel_axis=2, fill_mode='nearest') * 255\n",
    "            for _ in range(3)]\n",
    "        \n",
    "        for img_ in imgs:\n",
    "            shifted_img = img_.astype(np.uint8)\n",
    "            shifted_img = rgb2grey(shifted_img)\n",
    "            x_train.append(shifted_img)\n",
    "            y_train.append(digit)\n",
    "\n",
    "for digit in range(NUM_CLASSES):\n",
    "    directory = TEST_DIRECTORY_PATH + str(digit) + '/'\n",
    "    files = next(os.walk(directory))[2]\n",
    "    \n",
    "    for filename in files:\n",
    "        img = imread(directory + filename)\n",
    "        img = skimage.img_as_float(img)\n",
    "        imgs = [\n",
    "            random_shift(img, wrg=0.1, hrg=0.3, row_axis=0,\n",
    "                         col_axis=1, channel_axis=2, fill_mode='nearest') * 255\n",
    "            for _ in range(3)]\n",
    "        \n",
    "        for img_ in imgs:\n",
    "            shifted_img = img_.astype(np.uint8)\n",
    "            shifted_img = rgb2grey(shifted_img)\n",
    "            x_test.append(shifted_img)\n",
    "            y_test.append(digit)\n",
    "        \n",
    "x_train = np.asarray(x_train)\n",
    "x_train = x_train.reshape(x_train.shape[0], IMG_ROWS, IMG_COLS, 1)\n",
    "\n",
    "x_test = np.asarray(x_test)\n",
    "x_test = x_test.reshape(x_test.shape[0], IMG_ROWS, IMG_COLS, 1)\n",
    "\n",
    "input_shape = (IMG_ROWS, IMG_COLS, 1)\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
    "y_test = keras.utils.to_categorical(y_test, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T07:29:52.001588Z",
     "start_time": "2019-01-28T07:29:51.919396Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NUM_CLASSES, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T07:29:52.223641Z",
     "start_time": "2019-01-28T07:29:52.002848Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=keras.losses.categorical_crossentropy,\n",
    "    optimizer=keras.optimizers.Adadelta(),\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T07:34:26.202773Z",
     "start_time": "2019-01-28T07:29:52.224923Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9393 samples, validate on 2310 samples\n",
      "Epoch 1/150\n",
      "9393/9393 [==============================] - 2s 259us/step - loss: 1.8035 - acc: 0.4313 - val_loss: 1.3117 - val_acc: 0.6069\n",
      "Epoch 2/150\n",
      "9393/9393 [==============================] - 2s 205us/step - loss: 1.0142 - acc: 0.6714 - val_loss: 0.8343 - val_acc: 0.7433\n",
      "Epoch 3/150\n",
      "9393/9393 [==============================] - 2s 178us/step - loss: 0.6498 - acc: 0.7944 - val_loss: 0.6027 - val_acc: 0.8173\n",
      "Epoch 4/150\n",
      "9393/9393 [==============================] - 2s 187us/step - loss: 0.4288 - acc: 0.8663 - val_loss: 0.3171 - val_acc: 0.9160\n",
      "Epoch 5/150\n",
      "9393/9393 [==============================] - 2s 185us/step - loss: 0.3211 - acc: 0.9042 - val_loss: 0.2566 - val_acc: 0.9242\n",
      "Epoch 6/150\n",
      "9393/9393 [==============================] - 2s 221us/step - loss: 0.2404 - acc: 0.9294 - val_loss: 0.1735 - val_acc: 0.9567\n",
      "Epoch 7/150\n",
      "9393/9393 [==============================] - 2s 195us/step - loss: 0.2079 - acc: 0.9401 - val_loss: 0.1366 - val_acc: 0.9662\n",
      "Epoch 8/150\n",
      "9393/9393 [==============================] - 2s 198us/step - loss: 0.1722 - acc: 0.9490 - val_loss: 0.1538 - val_acc: 0.9567\n",
      "Epoch 9/150\n",
      "9393/9393 [==============================] - 2s 189us/step - loss: 0.1445 - acc: 0.9603 - val_loss: 0.0996 - val_acc: 0.9762\n",
      "Epoch 10/150\n",
      "9393/9393 [==============================] - 2s 181us/step - loss: 0.1400 - acc: 0.9577 - val_loss: 0.1250 - val_acc: 0.9701\n",
      "Epoch 11/150\n",
      "9393/9393 [==============================] - 2s 203us/step - loss: 0.1186 - acc: 0.9682 - val_loss: 0.0920 - val_acc: 0.9771\n",
      "Epoch 12/150\n",
      "9393/9393 [==============================] - 2s 175us/step - loss: 0.1025 - acc: 0.9725 - val_loss: 0.0859 - val_acc: 0.9758\n",
      "Epoch 13/150\n",
      "9393/9393 [==============================] - 2s 178us/step - loss: 0.0888 - acc: 0.9750 - val_loss: 0.0694 - val_acc: 0.9844\n",
      "Epoch 14/150\n",
      "9393/9393 [==============================] - 2s 205us/step - loss: 0.0899 - acc: 0.9739 - val_loss: 0.0589 - val_acc: 0.9840\n",
      "Epoch 15/150\n",
      "9393/9393 [==============================] - 2s 224us/step - loss: 0.0812 - acc: 0.9770 - val_loss: 0.0746 - val_acc: 0.9788\n",
      "Epoch 16/150\n",
      "9393/9393 [==============================] - 2s 189us/step - loss: 0.0753 - acc: 0.9790 - val_loss: 0.0577 - val_acc: 0.9853\n",
      "Epoch 17/150\n",
      "9393/9393 [==============================] - 2s 203us/step - loss: 0.0736 - acc: 0.9801 - val_loss: 0.0565 - val_acc: 0.9861\n",
      "Epoch 18/150\n",
      "9393/9393 [==============================] - 2s 193us/step - loss: 0.0685 - acc: 0.9802 - val_loss: 0.0561 - val_acc: 0.9848\n",
      "Epoch 19/150\n",
      "9393/9393 [==============================] - 2s 197us/step - loss: 0.0529 - acc: 0.9857 - val_loss: 0.0511 - val_acc: 0.9874\n",
      "Epoch 20/150\n",
      "9393/9393 [==============================] - 1s 157us/step - loss: 0.0602 - acc: 0.9819 - val_loss: 0.0550 - val_acc: 0.9857\n",
      "Epoch 21/150\n",
      "9393/9393 [==============================] - 2s 171us/step - loss: 0.0554 - acc: 0.9841 - val_loss: 0.0468 - val_acc: 0.9879\n",
      "Epoch 22/150\n",
      "9393/9393 [==============================] - 2s 196us/step - loss: 0.0495 - acc: 0.9847 - val_loss: 0.0479 - val_acc: 0.9879\n",
      "Epoch 23/150\n",
      "9393/9393 [==============================] - 2s 210us/step - loss: 0.0447 - acc: 0.9871 - val_loss: 0.0471 - val_acc: 0.9900\n",
      "Epoch 24/150\n",
      "9393/9393 [==============================] - 2s 205us/step - loss: 0.0433 - acc: 0.9866 - val_loss: 0.0477 - val_acc: 0.9874\n",
      "Epoch 25/150\n",
      "9393/9393 [==============================] - 2s 204us/step - loss: 0.0442 - acc: 0.9864 - val_loss: 0.0448 - val_acc: 0.9870\n",
      "Epoch 26/150\n",
      "9393/9393 [==============================] - 2s 197us/step - loss: 0.0465 - acc: 0.9864 - val_loss: 0.0384 - val_acc: 0.9892\n",
      "Epoch 27/150\n",
      "9393/9393 [==============================] - 2s 192us/step - loss: 0.0446 - acc: 0.9869 - val_loss: 0.0393 - val_acc: 0.9909\n",
      "Epoch 28/150\n",
      "9393/9393 [==============================] - 2s 192us/step - loss: 0.0423 - acc: 0.9878 - val_loss: 0.0419 - val_acc: 0.9883\n",
      "Epoch 29/150\n",
      "9393/9393 [==============================] - 2s 179us/step - loss: 0.0367 - acc: 0.9890 - val_loss: 0.0390 - val_acc: 0.9887\n",
      "Epoch 30/150\n",
      "9393/9393 [==============================] - 2s 199us/step - loss: 0.0372 - acc: 0.9884 - val_loss: 0.0339 - val_acc: 0.9900\n",
      "Epoch 31/150\n",
      "9393/9393 [==============================] - 2s 196us/step - loss: 0.0356 - acc: 0.9904 - val_loss: 0.0376 - val_acc: 0.9905\n",
      "Epoch 32/150\n",
      "9393/9393 [==============================] - 2s 168us/step - loss: 0.0318 - acc: 0.9906 - val_loss: 0.0368 - val_acc: 0.9896\n",
      "Epoch 33/150\n",
      "9393/9393 [==============================] - 2s 184us/step - loss: 0.0297 - acc: 0.9905 - val_loss: 0.0397 - val_acc: 0.9905\n",
      "Epoch 34/150\n",
      "9393/9393 [==============================] - 2s 195us/step - loss: 0.0320 - acc: 0.9898 - val_loss: 0.0341 - val_acc: 0.9913\n",
      "Epoch 35/150\n",
      "9393/9393 [==============================] - 2s 200us/step - loss: 0.0244 - acc: 0.9928 - val_loss: 0.0330 - val_acc: 0.9913\n",
      "Epoch 36/150\n",
      "9393/9393 [==============================] - 2s 200us/step - loss: 0.0282 - acc: 0.9915 - val_loss: 0.0326 - val_acc: 0.9913\n",
      "Epoch 37/150\n",
      "9393/9393 [==============================] - 2s 209us/step - loss: 0.0301 - acc: 0.9913 - val_loss: 0.0309 - val_acc: 0.9909\n",
      "Epoch 38/150\n",
      "9393/9393 [==============================] - 2s 192us/step - loss: 0.0269 - acc: 0.9921 - val_loss: 0.0398 - val_acc: 0.9905\n",
      "Epoch 39/150\n",
      "9393/9393 [==============================] - 2s 196us/step - loss: 0.0262 - acc: 0.9928 - val_loss: 0.0362 - val_acc: 0.9909\n",
      "Epoch 40/150\n",
      "9393/9393 [==============================] - 2s 189us/step - loss: 0.0226 - acc: 0.9932 - val_loss: 0.0349 - val_acc: 0.9909\n",
      "Epoch 41/150\n",
      "9393/9393 [==============================] - 2s 177us/step - loss: 0.0276 - acc: 0.9924 - val_loss: 0.0287 - val_acc: 0.9918\n",
      "Epoch 42/150\n",
      "9393/9393 [==============================] - 2s 208us/step - loss: 0.0231 - acc: 0.9939 - val_loss: 0.0347 - val_acc: 0.9905\n",
      "Epoch 43/150\n",
      "9393/9393 [==============================] - 2s 205us/step - loss: 0.0242 - acc: 0.9933 - val_loss: 0.0379 - val_acc: 0.9913\n",
      "Epoch 44/150\n",
      "9393/9393 [==============================] - 2s 203us/step - loss: 0.0238 - acc: 0.9938 - val_loss: 0.0313 - val_acc: 0.9926\n",
      "Epoch 45/150\n",
      "9393/9393 [==============================] - 2s 191us/step - loss: 0.0218 - acc: 0.9928 - val_loss: 0.0350 - val_acc: 0.9918\n",
      "Epoch 46/150\n",
      "9393/9393 [==============================] - 2s 210us/step - loss: 0.0231 - acc: 0.9943 - val_loss: 0.0370 - val_acc: 0.9913\n",
      "Epoch 47/150\n",
      "9393/9393 [==============================] - 2s 190us/step - loss: 0.0233 - acc: 0.9924 - val_loss: 0.0409 - val_acc: 0.9887\n",
      "Epoch 48/150\n",
      "9393/9393 [==============================] - 2s 207us/step - loss: 0.0199 - acc: 0.9952 - val_loss: 0.0326 - val_acc: 0.9913\n",
      "Epoch 49/150\n",
      "9393/9393 [==============================] - 2s 187us/step - loss: 0.0207 - acc: 0.9937 - val_loss: 0.0300 - val_acc: 0.9926\n",
      "Epoch 50/150\n",
      "9393/9393 [==============================] - 2s 168us/step - loss: 0.0201 - acc: 0.9941 - val_loss: 0.0462 - val_acc: 0.9909\n",
      "Epoch 51/150\n",
      "9393/9393 [==============================] - 2s 208us/step - loss: 0.0208 - acc: 0.9938 - val_loss: 0.0275 - val_acc: 0.9944\n",
      "Epoch 52/150\n",
      "9393/9393 [==============================] - 2s 192us/step - loss: 0.0183 - acc: 0.9952 - val_loss: 0.0347 - val_acc: 0.9918\n",
      "Epoch 53/150\n",
      "9393/9393 [==============================] - 2s 196us/step - loss: 0.0191 - acc: 0.9947 - val_loss: 0.0348 - val_acc: 0.9926\n",
      "Epoch 54/150\n",
      "9393/9393 [==============================] - 2s 187us/step - loss: 0.0177 - acc: 0.9950 - val_loss: 0.0306 - val_acc: 0.9935\n",
      "Epoch 55/150\n",
      "9393/9393 [==============================] - 2s 190us/step - loss: 0.0139 - acc: 0.9965 - val_loss: 0.0234 - val_acc: 0.9948\n",
      "Epoch 56/150\n",
      "9393/9393 [==============================] - 2s 208us/step - loss: 0.0141 - acc: 0.9956 - val_loss: 0.0235 - val_acc: 0.9939\n",
      "Epoch 57/150\n",
      "9393/9393 [==============================] - 2s 164us/step - loss: 0.0173 - acc: 0.9951 - val_loss: 0.0293 - val_acc: 0.9922\n",
      "Epoch 58/150\n",
      "9393/9393 [==============================] - 1s 156us/step - loss: 0.0156 - acc: 0.9961 - val_loss: 0.0293 - val_acc: 0.9926\n",
      "Epoch 59/150\n",
      "9393/9393 [==============================] - 2s 172us/step - loss: 0.0169 - acc: 0.9943 - val_loss: 0.0269 - val_acc: 0.9926\n",
      "Epoch 60/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9393/9393 [==============================] - 2s 209us/step - loss: 0.0161 - acc: 0.9955 - val_loss: 0.0289 - val_acc: 0.9926\n",
      "Epoch 61/150\n",
      "9393/9393 [==============================] - 2s 200us/step - loss: 0.0138 - acc: 0.9958 - val_loss: 0.0291 - val_acc: 0.9935\n",
      "Epoch 62/150\n",
      "9393/9393 [==============================] - 2s 177us/step - loss: 0.0128 - acc: 0.9961 - val_loss: 0.0247 - val_acc: 0.9935\n",
      "Epoch 63/150\n",
      "9393/9393 [==============================] - 2s 201us/step - loss: 0.0170 - acc: 0.9945 - val_loss: 0.0351 - val_acc: 0.9926\n",
      "Epoch 64/150\n",
      "9393/9393 [==============================] - 2s 215us/step - loss: 0.0150 - acc: 0.9962 - val_loss: 0.0321 - val_acc: 0.9922\n",
      "Epoch 65/150\n",
      "9393/9393 [==============================] - 2s 200us/step - loss: 0.0136 - acc: 0.9960 - val_loss: 0.0291 - val_acc: 0.9935\n",
      "Epoch 66/150\n",
      "9393/9393 [==============================] - 2s 188us/step - loss: 0.0166 - acc: 0.9950 - val_loss: 0.0282 - val_acc: 0.9926\n",
      "Epoch 67/150\n",
      "9393/9393 [==============================] - 2s 197us/step - loss: 0.0144 - acc: 0.9956 - val_loss: 0.0252 - val_acc: 0.9931\n",
      "Epoch 68/150\n",
      "9393/9393 [==============================] - 2s 209us/step - loss: 0.0168 - acc: 0.9947 - val_loss: 0.0300 - val_acc: 0.9935\n",
      "Epoch 69/150\n",
      "9393/9393 [==============================] - 2s 197us/step - loss: 0.0139 - acc: 0.9953 - val_loss: 0.0272 - val_acc: 0.9935\n",
      "Epoch 70/150\n",
      "9393/9393 [==============================] - 2s 195us/step - loss: 0.0125 - acc: 0.9961 - val_loss: 0.0306 - val_acc: 0.9935\n",
      "Epoch 71/150\n",
      "9393/9393 [==============================] - 2s 168us/step - loss: 0.0108 - acc: 0.9968 - val_loss: 0.0254 - val_acc: 0.9939\n",
      "Epoch 72/150\n",
      "9393/9393 [==============================] - 2s 203us/step - loss: 0.0135 - acc: 0.9955 - val_loss: 0.0267 - val_acc: 0.9935\n",
      "Epoch 73/150\n",
      "9393/9393 [==============================] - 2s 192us/step - loss: 0.0121 - acc: 0.9962 - val_loss: 0.0296 - val_acc: 0.9926\n",
      "Epoch 74/150\n",
      "9393/9393 [==============================] - 2s 172us/step - loss: 0.0128 - acc: 0.9962 - val_loss: 0.0286 - val_acc: 0.9935\n",
      "Epoch 75/150\n",
      "9393/9393 [==============================] - 2s 179us/step - loss: 0.0149 - acc: 0.9965 - val_loss: 0.0264 - val_acc: 0.9939\n",
      "Epoch 76/150\n",
      "9393/9393 [==============================] - 2s 187us/step - loss: 0.0131 - acc: 0.9966 - val_loss: 0.0233 - val_acc: 0.9935\n",
      "Epoch 77/150\n",
      "9393/9393 [==============================] - 2s 191us/step - loss: 0.0110 - acc: 0.9971 - val_loss: 0.0261 - val_acc: 0.9935\n",
      "Epoch 78/150\n",
      "9393/9393 [==============================] - 2s 166us/step - loss: 0.0114 - acc: 0.9968 - val_loss: 0.0299 - val_acc: 0.9931\n",
      "Epoch 79/150\n",
      "9393/9393 [==============================] - 2s 215us/step - loss: 0.0100 - acc: 0.9963 - val_loss: 0.0276 - val_acc: 0.9935\n",
      "Epoch 80/150\n",
      "9393/9393 [==============================] - 2s 208us/step - loss: 0.0108 - acc: 0.9967 - val_loss: 0.0274 - val_acc: 0.9926\n",
      "Epoch 81/150\n",
      "9393/9393 [==============================] - 2s 167us/step - loss: 0.0126 - acc: 0.9967 - val_loss: 0.0240 - val_acc: 0.9935\n",
      "Epoch 82/150\n",
      "9393/9393 [==============================] - 2s 203us/step - loss: 0.0092 - acc: 0.9970 - val_loss: 0.0233 - val_acc: 0.9935\n",
      "Epoch 83/150\n",
      "9393/9393 [==============================] - 2s 210us/step - loss: 0.0110 - acc: 0.9969 - val_loss: 0.0248 - val_acc: 0.9935\n",
      "Epoch 84/150\n",
      "9393/9393 [==============================] - 2s 175us/step - loss: 0.0108 - acc: 0.9972 - val_loss: 0.0285 - val_acc: 0.9926\n",
      "Epoch 85/150\n",
      "9393/9393 [==============================] - 2s 189us/step - loss: 0.0111 - acc: 0.9969 - val_loss: 0.0267 - val_acc: 0.9944\n",
      "Epoch 86/150\n",
      "9393/9393 [==============================] - 2s 236us/step - loss: 0.0114 - acc: 0.9965 - val_loss: 0.0252 - val_acc: 0.9944\n",
      "Epoch 87/150\n",
      "9393/9393 [==============================] - 2s 211us/step - loss: 0.0131 - acc: 0.9964 - val_loss: 0.0233 - val_acc: 0.9944\n",
      "Epoch 88/150\n",
      "9393/9393 [==============================] - 2s 205us/step - loss: 0.0112 - acc: 0.9968 - val_loss: 0.0252 - val_acc: 0.9948\n",
      "Epoch 89/150\n",
      "9393/9393 [==============================] - 2s 160us/step - loss: 0.0118 - acc: 0.9957 - val_loss: 0.0282 - val_acc: 0.9926\n",
      "Epoch 90/150\n",
      "9393/9393 [==============================] - 2s 194us/step - loss: 0.0086 - acc: 0.9972 - val_loss: 0.0247 - val_acc: 0.9931\n",
      "Epoch 91/150\n",
      "9393/9393 [==============================] - 2s 196us/step - loss: 0.0117 - acc: 0.9973 - val_loss: 0.0264 - val_acc: 0.9939\n",
      "Epoch 92/150\n",
      "9393/9393 [==============================] - 2s 196us/step - loss: 0.0098 - acc: 0.9970 - val_loss: 0.0254 - val_acc: 0.9944\n",
      "Epoch 93/150\n",
      "9393/9393 [==============================] - 2s 191us/step - loss: 0.0095 - acc: 0.9971 - val_loss: 0.0227 - val_acc: 0.9948\n",
      "Epoch 94/150\n",
      "9393/9393 [==============================] - 2s 181us/step - loss: 0.0115 - acc: 0.9969 - val_loss: 0.0222 - val_acc: 0.9948\n",
      "Epoch 95/150\n",
      "9393/9393 [==============================] - 2s 215us/step - loss: 0.0107 - acc: 0.9964 - val_loss: 0.0205 - val_acc: 0.9944\n",
      "Epoch 96/150\n",
      "9393/9393 [==============================] - 2s 212us/step - loss: 0.0085 - acc: 0.9973 - val_loss: 0.0262 - val_acc: 0.9944\n",
      "Epoch 97/150\n",
      "9393/9393 [==============================] - 2s 202us/step - loss: 0.0120 - acc: 0.9967 - val_loss: 0.0258 - val_acc: 0.9935\n",
      "Epoch 98/150\n",
      "9393/9393 [==============================] - 2s 179us/step - loss: 0.0096 - acc: 0.9964 - val_loss: 0.0239 - val_acc: 0.9939\n",
      "Epoch 99/150\n",
      "9393/9393 [==============================] - 2s 201us/step - loss: 0.0093 - acc: 0.9970 - val_loss: 0.0249 - val_acc: 0.9944\n",
      "Epoch 100/150\n",
      "9393/9393 [==============================] - 2s 201us/step - loss: 0.0079 - acc: 0.9977 - val_loss: 0.0239 - val_acc: 0.9944\n",
      "Epoch 101/150\n",
      "9393/9393 [==============================] - 2s 165us/step - loss: 0.0087 - acc: 0.9971 - val_loss: 0.0291 - val_acc: 0.9939\n",
      "Epoch 102/150\n",
      "9393/9393 [==============================] - 2s 197us/step - loss: 0.0092 - acc: 0.9970 - val_loss: 0.0255 - val_acc: 0.9939\n",
      "Epoch 103/150\n",
      "9393/9393 [==============================] - 2s 202us/step - loss: 0.0115 - acc: 0.9969 - val_loss: 0.0217 - val_acc: 0.9952\n",
      "Epoch 104/150\n",
      "9393/9393 [==============================] - 2s 200us/step - loss: 0.0083 - acc: 0.9976 - val_loss: 0.0231 - val_acc: 0.9952\n",
      "Epoch 105/150\n",
      "9393/9393 [==============================] - 2s 188us/step - loss: 0.0085 - acc: 0.9970 - val_loss: 0.0213 - val_acc: 0.9952\n",
      "Epoch 106/150\n",
      "9393/9393 [==============================] - 2s 203us/step - loss: 0.0080 - acc: 0.9974 - val_loss: 0.0232 - val_acc: 0.9948\n",
      "Epoch 107/150\n",
      "9393/9393 [==============================] - 2s 199us/step - loss: 0.0140 - acc: 0.9966 - val_loss: 0.0215 - val_acc: 0.9944\n",
      "Epoch 108/150\n",
      "9393/9393 [==============================] - 2s 202us/step - loss: 0.0098 - acc: 0.9970 - val_loss: 0.0196 - val_acc: 0.9952\n",
      "Epoch 109/150\n",
      "9393/9393 [==============================] - 2s 187us/step - loss: 0.0091 - acc: 0.9972 - val_loss: 0.0221 - val_acc: 0.9948\n",
      "Epoch 110/150\n",
      "9393/9393 [==============================] - 2s 177us/step - loss: 0.0086 - acc: 0.9977 - val_loss: 0.0217 - val_acc: 0.9948\n",
      "Epoch 111/150\n",
      "9393/9393 [==============================] - 2s 181us/step - loss: 0.0100 - acc: 0.9978 - val_loss: 0.0205 - val_acc: 0.9939\n",
      "Epoch 112/150\n",
      "9393/9393 [==============================] - 2s 176us/step - loss: 0.0076 - acc: 0.9977 - val_loss: 0.0194 - val_acc: 0.9957\n",
      "Epoch 113/150\n",
      "9393/9393 [==============================] - 2s 205us/step - loss: 0.0067 - acc: 0.9974 - val_loss: 0.0216 - val_acc: 0.9944\n",
      "Epoch 114/150\n",
      "9393/9393 [==============================] - 2s 180us/step - loss: 0.0066 - acc: 0.9980 - val_loss: 0.0221 - val_acc: 0.9944\n",
      "Epoch 115/150\n",
      "9393/9393 [==============================] - 1s 151us/step - loss: 0.0074 - acc: 0.9977 - val_loss: 0.0218 - val_acc: 0.9948\n",
      "Epoch 116/150\n",
      "9393/9393 [==============================] - 2s 197us/step - loss: 0.0084 - acc: 0.9981 - val_loss: 0.0209 - val_acc: 0.9952\n",
      "Epoch 117/150\n",
      "9393/9393 [==============================] - 2s 192us/step - loss: 0.0090 - acc: 0.9972 - val_loss: 0.0233 - val_acc: 0.9952\n",
      "Epoch 118/150\n",
      "9393/9393 [==============================] - 2s 201us/step - loss: 0.0065 - acc: 0.9979 - val_loss: 0.0228 - val_acc: 0.9948\n",
      "Epoch 119/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9393/9393 [==============================] - 2s 207us/step - loss: 0.0065 - acc: 0.9982 - val_loss: 0.0200 - val_acc: 0.9952\n",
      "Epoch 120/150\n",
      "9393/9393 [==============================] - 2s 178us/step - loss: 0.0092 - acc: 0.9972 - val_loss: 0.0216 - val_acc: 0.9948\n",
      "Epoch 121/150\n",
      "9393/9393 [==============================] - 2s 193us/step - loss: 0.0096 - acc: 0.9971 - val_loss: 0.0213 - val_acc: 0.9948\n",
      "Epoch 122/150\n",
      "9393/9393 [==============================] - 2s 174us/step - loss: 0.0075 - acc: 0.9977 - val_loss: 0.0216 - val_acc: 0.9952\n",
      "Epoch 123/150\n",
      "9393/9393 [==============================] - 2s 183us/step - loss: 0.0082 - acc: 0.9977 - val_loss: 0.0239 - val_acc: 0.9944\n",
      "Epoch 124/150\n",
      "9393/9393 [==============================] - 2s 184us/step - loss: 0.0052 - acc: 0.9981 - val_loss: 0.0234 - val_acc: 0.9948\n",
      "Epoch 125/150\n",
      "9393/9393 [==============================] - 2s 209us/step - loss: 0.0084 - acc: 0.9973 - val_loss: 0.0211 - val_acc: 0.9952\n",
      "Epoch 126/150\n",
      "9393/9393 [==============================] - 2s 226us/step - loss: 0.0063 - acc: 0.9976 - val_loss: 0.0244 - val_acc: 0.9948\n",
      "Epoch 127/150\n",
      "9393/9393 [==============================] - 2s 206us/step - loss: 0.0078 - acc: 0.9981 - val_loss: 0.0236 - val_acc: 0.9944\n",
      "Epoch 128/150\n",
      "9393/9393 [==============================] - 2s 194us/step - loss: 0.0079 - acc: 0.9974 - val_loss: 0.0225 - val_acc: 0.9948\n",
      "Epoch 129/150\n",
      "9393/9393 [==============================] - 2s 199us/step - loss: 0.0086 - acc: 0.9972 - val_loss: 0.0207 - val_acc: 0.9952\n",
      "Epoch 130/150\n",
      "9393/9393 [==============================] - 2s 202us/step - loss: 0.0062 - acc: 0.9980 - val_loss: 0.0219 - val_acc: 0.9944\n",
      "Epoch 131/150\n",
      "9393/9393 [==============================] - 2s 186us/step - loss: 0.0086 - acc: 0.9977 - val_loss: 0.0259 - val_acc: 0.9944\n",
      "Epoch 132/150\n",
      "9393/9393 [==============================] - 1s 157us/step - loss: 0.0058 - acc: 0.9980 - val_loss: 0.0243 - val_acc: 0.9948\n",
      "Epoch 133/150\n",
      "9393/9393 [==============================] - 2s 225us/step - loss: 0.0065 - acc: 0.9980 - val_loss: 0.0217 - val_acc: 0.9952\n",
      "Epoch 134/150\n",
      "9393/9393 [==============================] - 2s 198us/step - loss: 0.0064 - acc: 0.9987 - val_loss: 0.0222 - val_acc: 0.9948\n",
      "Epoch 135/150\n",
      "9393/9393 [==============================] - 2s 208us/step - loss: 0.0083 - acc: 0.9978 - val_loss: 0.0216 - val_acc: 0.9948\n",
      "Epoch 136/150\n",
      "9393/9393 [==============================] - 2s 185us/step - loss: 0.0054 - acc: 0.9980 - val_loss: 0.0198 - val_acc: 0.9952\n",
      "Epoch 137/150\n",
      "9393/9393 [==============================] - 2s 231us/step - loss: 0.0071 - acc: 0.9977 - val_loss: 0.0235 - val_acc: 0.9948\n",
      "Epoch 138/150\n",
      "9393/9393 [==============================] - 2s 193us/step - loss: 0.0070 - acc: 0.9978 - val_loss: 0.0278 - val_acc: 0.9952\n",
      "Epoch 139/150\n",
      "9393/9393 [==============================] - 2s 209us/step - loss: 0.0058 - acc: 0.9982 - val_loss: 0.0246 - val_acc: 0.9939\n",
      "Epoch 140/150\n",
      "9393/9393 [==============================] - 2s 190us/step - loss: 0.0078 - acc: 0.9976 - val_loss: 0.0218 - val_acc: 0.9948\n",
      "Epoch 141/150\n",
      "9393/9393 [==============================] - 2s 170us/step - loss: 0.0071 - acc: 0.9983 - val_loss: 0.0238 - val_acc: 0.9944\n",
      "Epoch 142/150\n",
      "9393/9393 [==============================] - 2s 195us/step - loss: 0.0063 - acc: 0.9982 - val_loss: 0.0224 - val_acc: 0.9948\n",
      "Epoch 143/150\n",
      "9393/9393 [==============================] - 2s 190us/step - loss: 0.0039 - acc: 0.9987 - val_loss: 0.0214 - val_acc: 0.9944\n",
      "Epoch 144/150\n",
      "9393/9393 [==============================] - 2s 187us/step - loss: 0.0059 - acc: 0.9982 - val_loss: 0.0234 - val_acc: 0.9948\n",
      "Epoch 145/150\n",
      "9393/9393 [==============================] - 2s 194us/step - loss: 0.0075 - acc: 0.9976 - val_loss: 0.0209 - val_acc: 0.9948\n",
      "Epoch 146/150\n",
      "9393/9393 [==============================] - 2s 193us/step - loss: 0.0079 - acc: 0.9974 - val_loss: 0.0239 - val_acc: 0.9944\n",
      "Epoch 147/150\n",
      "9393/9393 [==============================] - 2s 213us/step - loss: 0.0090 - acc: 0.9972 - val_loss: 0.0231 - val_acc: 0.9939\n",
      "Epoch 148/150\n",
      "9393/9393 [==============================] - 2s 200us/step - loss: 0.0065 - acc: 0.9982 - val_loss: 0.0195 - val_acc: 0.9961\n",
      "Epoch 149/150\n",
      "9393/9393 [==============================] - 2s 208us/step - loss: 0.0060 - acc: 0.9977 - val_loss: 0.0257 - val_acc: 0.9952\n",
      "Epoch 150/150\n",
      "9393/9393 [==============================] - 2s 222us/step - loss: 0.0055 - acc: 0.9978 - val_loss: 0.0242 - val_acc: 0.9952\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3950eb0be0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=128,\n",
    "    epochs=150,\n",
    "    verbose=1,\n",
    "    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T07:34:26.306875Z",
     "start_time": "2019-01-28T07:34:26.204092Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.024197186832275862\n",
      "Test accuracy: 0.9952380952380953\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T07:34:40.029134Z",
     "start_time": "2019-01-28T07:34:40.009572Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save('../taiko/external/mnist_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
